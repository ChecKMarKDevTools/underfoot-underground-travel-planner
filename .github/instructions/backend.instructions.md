---
applyTo: backend/**/*
---

# Copilot Instructions for Backend

> ï¿½ï¿½ï¸ **Underfoot Backend** â€” single-agent orchestrator for "underground" travel picks.
> âš™ï¸ Python 3.12+, FastAPI, Poetry. One OpenAI batch call.
> ğŸ¯ Goal: reliably return **4â€“6** items with **Near(ish) By** + rich debug.

---

## Tech & Constraints

- ğŸ **Runtime:** Python 3.12.11+
- ğŸš€ **Framework:** FastAPI with async/await
- ğŸ“¦ **Package Manager:** Poetry
- ğŸ§ª **Testing:** pytest with coverage â‰¥30% threshold
- ğŸ¨ **Style:** Black formatter, Ruff linter, type hints encouraged
- ğŸ”‘ **Secrets:** Environment variables via Pydantic settings. Never leak in logs/responses.
- ğŸŒ **CORS:** Restrict to allowed origins only

---

## Code Quality Rules

### SonarQube Compliance

- âš ï¸ **python:S1244** â€” Never use equality (`==`, `!=`) with floats. Use tolerance-based comparison:
  ```python
  # âŒ BAD
  if score == 0.5:
  
  # âœ… GOOD
  if abs(score - 0.5) < 0.0001:
  # or use math.isclose()
  if math.isclose(score, 0.5, rel_tol=1e-9):
  ```

### Python Best Practices

- Use Pydantic `BaseModel` for request/response validation
- Prefer composition over inheritance
- Keep functions pure where possible (no side effects)
- Async/await for I/O operations (OpenAI, external APIs, cache)
- Custom exceptions inherit from `UnderfootError` base class

---

## Project Structure

```
backend/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config/          # Settings, constants
â”‚   â”œâ”€â”€ middleware/      # CORS, security, tracing
â”‚   â”œâ”€â”€ models/          # Pydantic models (request/response/domain)
â”‚   â”œâ”€â”€ services/        # OpenAI, geocoding, scoring, search, cache
â”‚   â”œâ”€â”€ utils/           # Errors, logger, validators, sanitizers
â”‚   â””â”€â”€ workers/         # Main chat worker orchestration
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ unit/            # Fast isolated tests
â”‚   â””â”€â”€ integration/     # External service mocks
â””â”€â”€ pyproject.toml       # Poetry config + pytest settings
```

---

## Endpoints

### `POST /chat`

**Input**

```json
{
  "message": "Pikeville KY next week for 3 days, outdoors",
  "limit": 5,
  "force": false
}
```

**Process**

1. ğŸ“ **Parse** via OpenAI â†’ `{ location, start_date, end_date, vibe }`
2. ğŸ“ **Geocode** location to lat/lon
3. ğŸ” **Tiered search** (A: 10mi â†’ B: 20mi â†’ C: 40mi)
   - Stop when â‰¥4 candidates found
4. ğŸ§¹ **Filter + dedupe** (blocklist, name/URL dedup)
5. ğŸ§  **Rank** with single OpenAI batch call
6. ğŸ’¬ **Compose** reply in Underfoot voice
7. ğŸ“Š Return structured response + debug payload

**Output**

```json
{
  "reply": "Here's what I found...",
  "places": [...],
  "debug": {
    "request_id": "uf_...",
    "execution_time_ms": 1234,
    "parsed": {...},
    "radius_core": 10,
    "radius_used": 20,
    "counts": {...},
    "errors": [],
    "cache": "hit|miss"
  }
}
```

### `POST /normalize-location`

Geocodes location string to standardized format with lat/lon.

### `GET /health`

Returns service health + dependency status.

---

## Environment Variables

```bash
OPENAI_API_KEY=sk-...
OPENAI_MODEL=gpt-4o-mini
DEFAULT_RADIUS_MILES=10
MAX_RADIUS_MILES=40
CACHE_TTL_SECONDS=86400  # 24h prod, 60s dev
SERPAPI_KEY=...          # Optional: SERP search
EVENTBRITE_TOKEN=...     # Optional: events
REDDIT_CLIENT_ID=...     # Optional: Reddit posts
```

---

## Models & Validation

### Request Models (`src/models/request_models.py`)

- `SearchRequest`: message (5-500 chars), limit (1-10), force (bool)
- `NormalizeLocationRequest`: location string, optional confidence threshold
- Input sanitization via Pydantic validators (strip HTML, normalize whitespace)

### Response Models (`src/models/response_models.py`)

- `SearchResponse`: reply, places[], debug
- `DebugInfo`: request_id, execution_time_ms, cache, parsed, counts, errors
- `HealthResponse`: status, timestamp, elapsed_ms, dependencies, version
- `ErrorResponse`: error, message, request_id, timestamp, context

### Domain Models (`src/models/domain_models.py`)

- `ParsedUserInput`: location, start_date, end_date, vibe
- `SearchResult`: name, description, url, source, distance_miles, score

---

## Error Handling

### Custom Exceptions (`src/utils/errors.py`)

- `UnderfootError` â€” Base with status_code, error_code, context
- `ValidationError` â€” 400 for bad input
- `RateLimitError` â€” 429 with retry_after
- `UpstreamError` â€” 502 for external API failures
- `CacheError` â€” 500 for cache operations

### Retry Logic

- ï¿½ï¿½ Exponential backoff: 2s â†’ 4s â†’ 8s
- ğŸš¦ Retry on 429/5xx from external APIs
- ğŸ“Š Track retry counts in `debug.retries`

---

## Caching (`src/services/cache_service.py`)

- ğŸ—ï¸ **Key:** `{location}|{start_date}|{end_date}|{vibe}|{radius_bucket}`
- â±ï¸ **TTL:** Configurable via `CACHE_TTL_SECONDS`
- ğŸ”„ **Bypass:** `force=true` skips cache
- ğŸ’¾ **Backend:** In-memory dict (dev), Redis-ready interface

---

## Security

- ğŸ§½ **Sanitization:** Strip HTML/script tags, normalize whitespace (`input_sanitizer.py`)
- âœ… **Validation:** Pydantic models enforce length/format constraints (`input_validator.py`)
- ğŸš« **Blocklist:** Filter mainstream domains (TripAdvisor, Yelp, Facebook, Instagram)
- ğŸ” **CORS:** Middleware enforces allowed origins
- ğŸ›‘ **Error Responses:** Never expose stack traces or secrets to clients

---

## Performance & Cost

- ğŸ¯ **One OpenAI call** per `/chat` request (batch ranking)
- ğŸ“¦ **Cap per-source:** 6 candidates max before filtering
- â­ï¸ **Skip tiers:** Stop search if A tier yields 4-6 items
- ğŸ’¸ **Model choice:** `gpt-4o-mini` for cost efficiency

---

## Logging (`src/utils/logger.py`)

- ğŸ†” Generate `request_id` per request (format: `uf_{timestamp}_{random}`)
- ğŸ“Š Structured JSON logging with timings
- ğŸ”’ **Redact secrets** automatically (OpenAI keys, tokens)
- ğŸš« Don't log full prompts (only summaries/hashes)
- ğŸ“ˆ Track: execution_time_ms, token_usage, retry_counts, cache_hit_rate

---

## Testing

### Coverage Requirements

- ğŸ¯ **Threshold:** 30% minimum (enforced in CI)
- ğŸ“Š **Current:** 31.46% (passing)
- ğŸ§ª Run: `poetry run pytest --cov=src --cov-report=term-missing`

### Test Structure

- **Unit** (`tests/unit/`):
  - Models: Pydantic validation, field requirements
  - Utils: Errors, logger, validators, sanitizers
  - Services: Scoring, OpenAI parsing (mocked)
  
- **Integration** (`tests/integration/`):
  - Mock external APIs (OpenAI, SERP, Eventbrite, Reddit)
  - Test tiered search logic
  - Verify retry/backoff behavior

### Test Scenarios

- âœ… Valid input parsing
- âŒ Invalid input rejection (too short, too long, dangerous chars)
- ğŸ”„ Tier progression (A insufficient â†’ B â†’ C)
- ğŸš« Blocklist filtering
- ğŸ” Retry on 429/5xx with backoff
- ğŸ’¾ Cache hit/miss/force bypass
- ğŸ§® Floating-point comparisons use tolerance (python:S1244)

---

## Definition of Done

- ğŸ `/chat` returns **4â€“6** items consistently
- ğŸ•µï¸ Debug payload complete (timings, counts, cache status, retries)
- ğŸ“Š Coverage â‰¥30% with all tests passing
- ğŸ§¹ Passes: `ruff check`, `black --check`, `pytest`
- ğŸ”’ No secrets in logs or responses
- ğŸ“ Conventional commit messages
- ğŸš€ Ready for Cloudflare Workers deployment
